\graphicspath{{chapters/03_objectives/}}
\chapter{Objectives}

% The Objectives section summarizes the project rationale, the scientific hypothesis and the key experiments that have been planned to test the hypothesis (at least 1 page, not more than 2 pages).

Hi-C data is intrinsically hard to process due to several factors, among which the fact that it is represented by a huge, extremely sparse, upper triangular matrix; this leads to challenges both in terms of memory management and computational runtime, as well as processing in general. There exist some tools which allow to work with this type of data, notably those grouped under the Open Chromosome Collective\cite{openchromosomecollective}. Among these, cooler\cite{cooler2020} is used to handle data storage, while cooltools\cite{cooltools2022} can be used for general preprocessing and certain specific types of analysis (compartment and boundaries definition, feature and pattern pileup). 

Nevertheless, at the time of writing, it seems that very few tools for network analysis of Hi-C data exist yet\cite{chromatinnetworks2023}. This is probably because Hi-C data can be converted into very dense and high order networks, which are memory-demanding and difficult to handle. For this reason only standard analyses which have been optimized for memory efficiency can be currently conducted on them. Still, this is quite unexpected, given the fact that Hi-C contact matrices are examples of adjacency matrices, which are natural representations of graphs. Rephrasing for clarity, Hi-C contact matrices can be easily converted into weighted, undirected graphs, with nodes representing the bins in which the genome has been divided into, and edges representing the contacts among those regions. The weights of the edges can be defined as the raw numbers of contacts obtained from sequencing or (better) some normalized measure derived from them. Network analysis of Hi-C data would provide information complementary to the one obtained through current analysis techniques, thus allowing to better study and characterize chromatin conformation and its role. 

HiCONA is a package which aims to address this lack of tools for Hi-C data network analysis as well as the technical challenges in working with these networks; in order to do so, it provides some general functionalities which are useful regardless of the network analysis task of interest, as well as specialized version of network analysis algorithms already used in data science or other fields. Since the package was developed in Python3 using a fully object-oriented approach, it is easy to extend with any new functionalities or needs which may arise. Package functionalities can be grouped into three main tasks:
\begin{itemize}\tightlist
  \item Pixel preprocessing, which includes all steps required to prepare the pixels contained in the original data file, encompassing filtering, normalization and sparsification. These steps are aimed at achieving networks with fairly consistent properties in order to facilitate the comparison of different experiments, which is currently quite difficult due to the high variability tied to the Hi-C technique itself.
  \item Bin annotation manipulation, meaning some utility functions which can be used to add, or manipulate, bin annotations starting from bed-like files. This exploits the capability of networks to integrate data, in order to allow for more in depth and robust analysis. 
  \item Network generation and analysis. While the package itself provides some algorithms, another objective is to be able to integrate this tool with others, and for this reason import and export to standard graph file formats (such as .xml) is also supported.  
\end{itemize}

Hi-C data files can be quite large and cumbersome to work with; moreover network analysis itself is not trivial especially regarding memory usage. HiCONA strives to make possible to process almost any Hi-C data file even on laptops; for this reason, particularly demanding operations, such as the preprocessing, have been optimized keeping into account the specific properties of Hi-C data, in order to reduce memory usage and computational runtime by chunking, vectorizing and parallelizing operations.

As previously mentioned, the main focus of discussion will be pixel preprocessing.

% TODO: Maybe add something about reproducibility and requiring less coverage